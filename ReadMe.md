# Kafka Workshop Part 2: Schema Registry with Protobuf

In this exercise you will create a class library containing `.proto` files to define Protobuf schemas from which C# classes will be generated by both Consumer and Producer applications. This is a convenient way to share schema defintions among multiple projects. In the **Protos** folder you will create multiple versions of the `HelloReply` schema with properties that are added or subtracted in a way that is both forward and backwards compatible. There is a also a version that violates Protobuf schema evolution rules which will result in a serialization error when the Producer attempts to write it to Kafka.

> **Note**: Here is a blog post explaining the design of  the event stream processing framework: https://blog.tonysneed.com/2020/06/25/event-stream-processing-micro-framework-apache-kafka/.

### Prerequisites

1. Install [Docker Desktop](https://docs.docker.com/desktop/).
   - You will need at least 8 GB of available memory.
2. Open a terminal at the project root and run `docker-compose up --build -d`.
   - To check the running containers run `docker-compose ps`.
   - To bring down the containers run `docker-compose down`.
3. Open a browser to http://localhost:9021/.
   - Verify the cluster is healthy. (This may take a few minutes.)

> **Note**: Switch to the `after` branch to view the completed solution: `git checkout after`

## Proto Library

1. Create a **greet.v1.proto** file in **Protos** folder.
   - First delete **Placeholder.txt** from the **Protos** folder.
   - Note the `csharp_namespace` option which specifies the namespace in which the `HelloReply` class will be placed.
    ```protobuf
    syntax = "proto3";

    option csharp_namespace = "Protos.v1";

    // The response message containing the greetings.
    message HelloReply {
      string message = 1;
    }
    ```
2. Add Google.Protobuf, Grpc.Core, Grpc.Tools packages.
    ```bash
    dotnet add package Google.Protobuf
    dotnet add package Grpc.Core
    dotnet add package Grpc.Tools
    ```

## Usage

1. Start the **Consumer** console app (Ctrl+F5).

2. Set breakpoints in the **Worker** project to view the process flow.
   - Set breakpoints in the `HandleMessage` method of each handler.
   - Set a breakpoint in `eventProcessor.Process` in `KafkaWorker.ExecuteAsync`.
   - Set a breakpoint in `Host.CreateDefaultBuilder.ConfigureServices` in `Program.CreateHostBuilder`.
   - Press F5 to start the debugger.

3. Start the **Producer** console app (Ctrl+F5).
   - Enter the following values.
    ```
    1 Hello World
    2 Hello World
    3 Hello World
    4 Hello World
    5 Hello World
    ```

4. Note processing of the event stream for each message in the "raw-events" topic.
   - Notice that messages 1, 2 and 3 are all translated.
   - Notice that message 4 is filtered out because it is English.
   - Notice that message 5 fails validation because no language corresponds to message key 5.